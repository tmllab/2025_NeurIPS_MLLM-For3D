# "nuscenes" or "kitti"
dataset: scannet
mode: pretrain
#mode: 'source_free'
working_dir: output/reasonseg/scannet/
# if set to True, use cylindrical coordinates, otherwise use cartesian
cylindrical_coordinates: false
# size of the voxel in each dimension for cartesian coordinates,
# and in rho and z for cylindrical (angular is always 1°)
voxel_size: 0.05
batch_size: 2
# learning rate
lr: 0.1
sgd_momentum: 0.9
sgd_dampening: 0.1
weight_decay: 0.0001
num_epochs: 40
# used in superpixel loss only, drop points and pixels from the computation of the loss
dropout: 0.
# number of GPUs and CPU threads to use
num_gpus: 2
num_threads: 32
kernel_size: 3
model_n_out: 512
bn_momentum: 0.05
crop_size:
  - 224
  - 416
crop_ratio:
  - 1.5555555555555556
  - 1.8888888888888888
# point cloud backbone to use among "minkunet" and "voxelnet"
model_points: minkunet
# which image pretraining to chose among:
# 'imagenet','obow', 'pixpro', 'moco_v1', 'moco_v2', 'swav',
# 'deepcluster_v2', 'dino', 'moco_coco'
image_weights: moco_v2
#image_weights : None
# which image encoder to use (only imagenet is available with resnet18)
#images_encoder : "resnet50"
images_encoder: lisa
# which image decoder to use
# 'bilinear', 'unet', 'fpn', 'semseg', 'nnfe', 'dilation', 'ppkt'
decoder: dilation
# temperature parameter in the InfoNCE loss
NCE_temperature: 0.07
# number of positive matches in the InfoNCE loss
num_matches: 4096
# whether to use the true validation set or the custom parametrization set
training: training
# transformations to apply to the clouds
#transforms_images : ["RandomContrast", "RandomBrightness", "RandomSaturation", "RandomLighting"]
#transforms_images : ["ColorAugSSDTransform"]
transforms_images: []
transforms_clouds:
  - Rotation
  - FlipAxis
# transformations to apply to both the clouds and the images among:
transforms_mixed:
  - ResizedCrop
  - FlipHorizontal
text_augmentation: true
# which losses to use (note that multiple losses will be summed)
losses:
  - scannet_loss
# LISA inference
version: xinlai/LISA-7B-v1
precision: bf16
conv_type: llava_v1
vision_tower: openai/clip-vit-large-patch14
model_max_length: 512
local_rank: 0
image_size: 1024
use_mm_start_end: True
vis_save_path: ./vis_results
# dataRoot_scannet: "/vepfs/home/wangzhaoqing/runnan/datasets/scannet/scans/scans"
dataRoot_scannet: "/l/users/jiaxin.huang/jiaxin/dataset/scannet/raw/scans"
train_file: "/home/jiaxin.huang/jiaxin/scannet_train_small.txt"
val_file: "/home/jiaxin.huang/jiaxin/scannet_val_small_v2.txt"
dataRoot_images: "/l/users/jiaxin.huang/jiaxin/scannet_frames_25k"
# description_json: "/home/jiaxin.huang/jiaxin/description_all.json"

# 新增训练和验证描述文件路径
description_json_train: "/l/users/jiaxin.huang/jiaxin/intent3D/intention_sentence/train_samples_dict_vg_format_clean_duplicate.json"
description_json_val: "/l/users/jiaxin.huang/jiaxin/intent3D/intention_sentence/val_samples_dict_vg_format_clean_duplicate.json"

# which kind of superpixels to use
superpixels_type: slic
# only keep 1 in dataset_skip_step training examples (here use 100% of the data)
dataset_skip_step: 1
# path to weights to continue a previous training
resume_path: null

max_sweeps: 1

# WARNING: DO NOT CHANGE THE FOLLOWING PARAMETERS
# ===============================================
normalize_features: false
superpixel_size: 150